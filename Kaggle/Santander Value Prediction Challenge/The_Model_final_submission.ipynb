{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "from math import sqrt\n",
    "from sklearn import linear_model, ensemble, svm, model_selection, metrics\n",
    "from scipy import stats\n",
    "import gc\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.options.display.max_info_columns = 999\n",
    "pd.options.display.max_info_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_seq_items = 999\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.read_csv('clusters_6_opt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_2 = pd.read_csv('clusters_20_opt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_3 = pd.read_csv('clusters_60_opt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_train = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1 = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1',\n",
    "        '15ace8c9f', 'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9',\n",
    "        'd6bb78916', 'b43a7cfd5', '58232a6fb', '1702b5bf0', '324921c7b',\n",
    "        '62e59a501', '2ec5b290f', '241f0f867', 'fb49e4212', '66ace2992',\n",
    "        'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7', '1931ccfdd',\n",
    "        '703885424', '70feb1494', '491b9ee45', '23310aa6f', 'e176a204a',\n",
    "        '6619d81fc', '1db387535', 'fc99f9426', '91f701ba2', '0572565c2',\n",
    "        '190db8488', 'adb64ff71', 'c47340d97', 'c5a231d81', '0ff32eb98']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_imp = cols1[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test_compiled_leak = pd.read_csv('test_compiled_leak_36.csv')\n",
    "augmenation = test_compiled_leak[test_compiled_leak.compiled_leak !=0]\n",
    "aug = test.merge(augmenation, how='inner', on='ID')\n",
    "aug['target'] = aug.compiled_leak\n",
    "aug.drop(['compiled_leak'], inplace=True, axis=1)\n",
    "X = pd.concat([train,aug], ignore_index=True)\n",
    "X = X[cols_train]\n",
    "Y = X['target'].copy()\n",
    "Y = np.log1p(Y)\n",
    "X_train = X.drop(['ID','target'],axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[cols_train]\n",
    "Y = X['target'].copy()\n",
    "Y = np.log1p(Y)\n",
    "X_train = X.drop(['ID','target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zeros = pd.DataFrame({'Percent_zero':((X_train.values)==0).mean(axis=0),\n",
    "                           'Column' : X_train.columns})\n",
    "\n",
    "high_vol_columns = train_zeros['Column'][train_zeros['Percent_zero'] < 0.76].values\n",
    "low_vol_columns = train_zeros['Column'][train_zeros['Percent_zero'] >= 0.76].values\n",
    "\n",
    "low_vol_columns_to_drop = train_zeros['Column'][train_zeros['Percent_zero'] >= 0.62].values\n",
    "high_vol_columns_to_drop = train_zeros['Column'][train_zeros['Percent_zero'] < 0.62].values\n",
    "\n",
    "low_vol_columns_to_drop_1 = train_zeros['Column'][train_zeros['Percent_zero'] >= 0.76].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statsForHighLow(X1, df):\n",
    "    cluster_sets = {\"low\":low_vol_columns, \"high\":high_vol_columns}\n",
    "    for cluster_key in cluster_sets:\n",
    "        X1[\"count_not0_\"+cluster_key] = df[cluster_sets[cluster_key]].count(axis=1)\n",
    "        X1[\"sum_\"+cluster_key] = df[cluster_sets[cluster_key]].sum(axis=1)\n",
    "        X1[\"var_\"+cluster_key] = df[cluster_sets[cluster_key]].var(axis=1)\n",
    "        X1[\"median_\"+cluster_key] = df[cluster_sets[cluster_key]].median(axis=1)\n",
    "        X1[\"mean_\"+cluster_key] = df[cluster_sets[cluster_key]].mean(axis=1)\n",
    "        X1[\"std_\"+cluster_key] = df[cluster_sets[cluster_key]].std(axis=1)\n",
    "        X1[\"max_\"+cluster_key] = df[cluster_sets[cluster_key]].max(axis=1)\n",
    "        X1[\"min_\"+cluster_key] = df[cluster_sets[cluster_key]].min(axis=1)\n",
    "        X1[\"skew_\"+cluster_key] = df[cluster_sets[cluster_key]].skew(axis=1)\n",
    "        X1[\"kurtosis_\"+cluster_key] = df[cluster_sets[cluster_key]].kurtosis(axis=1) \n",
    "    return X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statsForClusters(X1, tmp, clusters, k):\n",
    "    for j in range(k):\n",
    "        try:\n",
    "            cols = clusters[clusters.cluster == j].feature.values\n",
    "            X1['mean_nonz_'+str(j)] = tmp[cols].mean(axis=1)\n",
    "            X1['std_nonz_'+str(j)] = tmp[cols].std(axis=1)\n",
    "            X1['median_nonz_'+str(j)] = tmp[cols].median(axis=1)\n",
    "            X1['range_'+str(j)] = tmp[cols].max(axis=1) - tmp[cols].min(axis=1)\n",
    "            X1['coef_var_nonz_'+str(j)] = (X1['std_nonz_'+str(j)]/ X1['mean_nonz_'+str(j)])*100\n",
    "            msk1 = np.ma.masked_invalid(tmp[cols])\n",
    "            X1['gmean_'+str(j)] = stats.mstats.gmean(msk1, axis=1)\n",
    "            X1['gmean/mean_'+str(j)] = X1['gmean_'+str(j)]/X1['mean_nonz_'+str(j)]\n",
    "            X1['count_nonz_'+str(j)] = tmp[cols].notnull().sum(axis=1)\n",
    "            X1['count_unique_'+str(j)] = tmp[cols].T.apply(lambda x: len(x.unique())-1)\n",
    "            mode_nonzero = stats.mode(tmp[cols], axis=1, nan_policy='omit')\n",
    "            X1['frequent_of_mode'+str(j)] = mode_nonzero[1].data\n",
    "            X1['mode_nonzero'+str(j)] = mode_nonzero[0].data\n",
    "            X1['mode_for_freq'+str(j)] = X1[X1['frequent_of_mode'+str(j)] > 3]['mode_nonzero'+str(j)]\n",
    "            X1.drop(['mode_nonzero'+str(j)], axis=1, inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "    return X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparingInput(df):\n",
    "    X1 = df.copy()\n",
    "    X1[X1 == 0] = np.nan\n",
    "    X1['mean'] = df.mean(axis=1)\n",
    "    X1['std'] = df.std(axis=1)\n",
    "    X1['var'] = df.var(axis=1)\n",
    "    X1['count_nonzero'] = np.count_nonzero(df, axis=1)\n",
    "    X1['unique/nonzero'] = df.T.apply(lambda x: len(x.unique())-1)/X1['count_nonzero']\n",
    "    X1['sum'] = df.sum(axis=1)\n",
    "    X1['mean_nonzero'] = X1['sum']/X1['count_nonzero']\n",
    "    X1['mean/mean_nonzero'] = X1['mean']/X1['mean_nonzero']\n",
    "    X1['kurtosis'] = stats.kurtosis(df, axis=1)\n",
    "    X1['skew'] = stats.skew(df, axis=1)\n",
    "    msk = np.ma.masked_where(df == 0, df)\n",
    "    X1['median_nonzero'] = np.ma.median(msk, axis=1)\n",
    "    X1['gmean'] = stats.mstats.gmean(msk, axis=1)\n",
    "    X1['min_nonzero'] = np.ma.min(msk, axis=1)\n",
    "    X1['std_nonzero'] = np.ma.std(msk, axis=1)\n",
    "    X1['coef_var_nonzero'] = (X1['std_nonzero']/ X1['mean_nonzero'])*100\n",
    "    X1['interquartile_range'] = stats.mstats.mquantiles(msk, prob=[0.75], axis=1) - stats.mstats.mquantiles(msk, prob=[0.25], axis=1)\n",
    "    X1['kurtosis_nonzero'] = stats.mstats.kurtosis(msk, fisher=False, axis=1)\n",
    "    X1['skewness_nonzero'] = stats.mstats.skew(msk, axis=1)\n",
    "    X1['gmean_mean_nonzero'] = X1['gmean']/X1['mean_nonzero']\n",
    "    X1['gmean_mean'] = X1['gmean']/X1['mean']\n",
    "    X1['inverse_gmean_mean_nonzero'] = X1['mean_nonzero']/X1['gmean']\n",
    "    X1['percentile_90'] = np.percentile(df, 90, axis=1)\n",
    "    X1['percentile_91'] = np.percentile(df, 91, axis=1)\n",
    "    X1['percentile_92'] = np.percentile(df, 92, axis=1)\n",
    "    X1['percentile_93'] = np.percentile(df, 93, axis=1)\n",
    "    X1['percentile_94'] = np.percentile(df, 94, axis=1)\n",
    "    X1['percentile_95'] = np.percentile(df, 95, axis=1)\n",
    "    X1['percentile_96'] = np.percentile(df, 96, axis=1)\n",
    "    X1['percentile_97'] = np.percentile(df, 97, axis=1)\n",
    "    X1['percentile_98'] = np.percentile(df, 98, axis=1)\n",
    "    X1['percentile_99'] = np.percentile(df, 99, axis=1)\n",
    "    X1['max'] = df.max(axis=1)\n",
    "    tmp = df.copy()\n",
    "    tmp[tmp == 0] = np.nan\n",
    "    mode_nonzero = stats.mode(tmp, axis=1, nan_policy='omit')\n",
    "    X1['frequent_of_mode'] = mode_nonzero[1].data\n",
    "    X1['mode_nonzero'] = mode_nonzero[0].data\n",
    "    X1['mode_for_freq'] = X1[X1.frequent_of_mode > 5].mode_nonzero\n",
    "    X1.drop(['mode_nonzero'], axis=1, inplace=True)\n",
    "    statsForClusters(X1, tmp, clusters, 6)\n",
    "    statsForHighLow(X1, tmp)\n",
    "    X2 = X1.drop(low_vol_columns_to_drop,axis=1)\n",
    "    X3 = tmp.copy()\n",
    "    msk2 = np.ma.masked_invalid(tmp[time_series_imp])\n",
    "    statsForClusters(X3, tmp, clusters, 6)\n",
    "    statsForHighLow(X3, tmp)\n",
    "    X4 = X3.drop(low_vol_columns_to_drop,axis=1)\n",
    "    X5 = X3.drop(high_vol_columns_to_drop,axis=1)\n",
    "    X6 = tmp.copy().drop(low_vol_columns_to_drop_1,axis=1)\n",
    "    statsForHighLow(X6, tmp)\n",
    "    X7 = X4.copy()\n",
    "    X8 = tmp[cols1].copy()\n",
    "    X9 = pd.DataFrame()\n",
    "    X7['last_nonz_index'] = pd.Series(np.ma.notmasked_edges(msk2, axis=1)[1][1])\n",
    "    X7['last_nonz'] = tmp[time_series_imp].ewm(alpha=1, ignore_na = True, axis=1).mean().iloc[:,-1]\n",
    "    X7['last_nonz_2'] = tmp[time_series_imp].ewm(alpha=1, ignore_na = True, axis=1).mean().iloc[:,-2]\n",
    "    X7['last_nonz_3'] = tmp[time_series_imp].ewm(alpha=1, ignore_na = True, axis=1).mean().iloc[:,-3]\n",
    "    X7['1_diff'] = X7['last_nonz'] - X7['last_nonz_2']\n",
    "    statsForClusters(X8, tmp, clusters_2, 20)\n",
    "    statsForClusters(X9, tmp, clusters_3, 60)\n",
    "    X2 = X2.loc[:, X2.std() != 0.0]\n",
    "    X4 = X4.loc[:, X4.std() != 0.0]\n",
    "    X5 = X5.loc[:, X5.std() != 0.0]\n",
    "    X6 = X6.loc[:, X6.std() != 0.0]\n",
    "    X7 = X7.loc[:, X7.std() != 0.0]\n",
    "    X8 = X8.loc[:, X8.std() != 0.0]\n",
    "    X9 = X9.loc[:, X9.std() != 0.0]\n",
    "    return [X2, X4, X5, X7, X8, X6, X9]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_for_model = preparingInput(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = input_for_model[0] #\n",
    "X2 = input_for_model[1]\n",
    "X3 = input_for_model[2]\n",
    "X4 = input_for_model[3]\n",
    "X5 = input_for_model[4]\n",
    "X6 = input_for_model[5]\n",
    "X7 = input_for_model[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_2 = {\n",
    "    'application': 'regression',\n",
    "    'metric': 'l2_root',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 150,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 2,\n",
    "    'learning_rate': 0.005, \n",
    "    'verbose': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_1 = {\n",
    "    'application': 'regression',\n",
    "    'metric': 'l2_root',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 120,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 2,\n",
    "    'learning_rate': 0.01, \n",
    "    'verbose': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(X, Y, parameters):\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    i=1\n",
    "    results = pd.DataFrame()\n",
    "    y_pred_test_oof = pd.DataFrame({'Y_oof': np.zeros(Y.shape)})\n",
    "    models = list()\n",
    "    for trainIdx, testIdx in cv.split(X, Y):\n",
    "        train_data = lgb.Dataset(X.values[trainIdx], label=Y.values[trainIdx])\n",
    "        test_data = lgb.Dataset(X.values[testIdx], label=Y.values[testIdx])\n",
    "        model = lgb.train(parameters,\n",
    "                       train_data,\n",
    "                       valid_sets=test_data,\n",
    "                       num_boost_round=1000,\n",
    "                       early_stopping_rounds=100)\n",
    "        y_pred_train = model.predict(X.values[trainIdx])\n",
    "        y_pred_test = model.predict(X.values[testIdx])\n",
    "        y_pred_test_oof.iloc[testIdx, 0] =  y_pred_test\n",
    "        models.append(model)\n",
    "        results.loc[i, 'train_RMSE'] = sqrt(mean_squared_error(y_pred_train, Y.values[trainIdx]))\n",
    "        results.loc[i, 'test_RMSE'] = sqrt(mean_squared_error(y_pred_test, Y.values[testIdx]))\n",
    "        i+=1\n",
    "    return [results, y_pred_test_oof, models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "training_2 = trainModel(X2, Y, parameters_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = training_2[0]\n",
    "print(results)\n",
    "print(\"Mean: {:4f}\".format(np.mean(results.test_RMSE)))\n",
    "print(\"Standart deviation: {:4f}\".format(np.std(results.test_RMSE)))\n",
    "print(\"OOF-rmse: \", sqrt(mean_squared_error(training_2[1], Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "training_1 = trainModel(X1, Y, parameters_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = training_1[0]\n",
    "print(results)\n",
    "print(\"Mean: {:4f}\".format(np.mean(results.test_RMSE)))\n",
    "print(\"Standart deviation: {:4f}\".format(np.std(results.test_RMSE)))\n",
    "print(\"OOF-rmse: \", sqrt(mean_squared_error(training_1[1], Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "training_3 = trainModel(X3, Y, parameters_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = training_3[0]\n",
    "print(results)\n",
    "print(\"Mean: {:4f}\".format(np.mean(results.test_RMSE)))\n",
    "print(\"Standart deviation: {:4f}\".format(np.std(results.test_RMSE)))\n",
    "print(\"OOF-rmse: \", sqrt(mean_squared_error(training_3[1], Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "training_4 = trainModel(X4, Y, parameters_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = training_4[0]\n",
    "print(results)\n",
    "print(\"Mean: {:4f}\".format(np.mean(results.test_RMSE)))\n",
    "print(\"Standart deviation: {:4f}\".format(np.std(results.test_RMSE)))\n",
    "print(\"OOF-rmse: \", sqrt(mean_squared_error(training_4[1], Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "training_5 = trainModel(X5, Y, parameters_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = training_5[0]\n",
    "print(results)\n",
    "print(\"Mean: {:4f}\".format(np.mean(results.test_RMSE)))\n",
    "print(\"Standart deviation: {:4f}\".format(np.std(results.test_RMSE)))\n",
    "print(\"OOF-rmse: \", sqrt(mean_squared_error(training_5[1], Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "training_6 = trainModel(X6, Y, parameters_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = training_6[0]\n",
    "print(results)\n",
    "print(\"Mean: {:4f}\".format(np.mean(results.test_RMSE)))\n",
    "print(\"Standart deviation: {:4f}\".format(np.std(results.test_RMSE)))\n",
    "print(\"OOF-rmse: \", sqrt(mean_squared_error(training_6[1], Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "training_7 = trainModel(X7, Y, parameters_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = training_7[0]\n",
    "print(results)\n",
    "print(\"Mean: {:4f}\".format(np.mean(results.test_RMSE)))\n",
    "print(\"Standart deviation: {:4f}\".format(np.std(results.test_RMSE)))\n",
    "print(\"OOF-rmse: \", sqrt(mean_squared_error(training_7[1], Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(mean_squared_error((0.2*training_1[1] + 0*training_2[1]  +0.07*training_3[1]+ 0.2*training_4[1]+0.15*training_5[1]+0.18*training_6[1] + 0.2*training_7[1]), Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del input_for_model, X1, X2, X3, X4, X5, X6, X7\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = preparingInput(test[cols_train.drop(['ID', 'target'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [training_1, training_2, training_3, training_4, training_5, training_6, training_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for j in training:\n",
    "    my_prediction = pd.DataFrame()\n",
    "    i=0\n",
    "    for i in range(5):\n",
    "        my_prediction[str(i)] = pd.Series(j[2][i].predict(input_test[k], num_iteration = j[2][i].best_iteration))\n",
    "        i+=1\n",
    "    my_predictions.append(pd.Series(my_prediction.mean(axis=1)))\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = 0.2*my_predictions[0] + 0.0*my_predictions[1]+0.1*my_predictions[2]+ 0.2*my_predictions[3]+0.15*my_predictions[4]+0.15*my_predictions[5] + 0.2*my_predictions[6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pred = np.expm1(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pred = np.expm1(my_predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame(test[['ID']]).reset_index().join(pd.DataFrame(my_pred, columns=['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = my_submission.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.to_csv('my_submission_new!_new!_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
