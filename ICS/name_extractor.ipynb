{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from pullenti_wrapper.langs import set_langs, UA\n",
    "from pullenti_wrapper.processor import Processor, PERSON\n",
    "set_langs([UA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NameSearch():\n",
    "    NAME_ENDINGS = [\"ев\", \"єв\", \"ив\", \"ів\", \"їв\", \n",
    "                   \"еві\", \"ева\", \"евим\", \"еву\", \"евої\", \"евій\", \"евою\", \"евому\",\n",
    "                   \"єві\", \"єву\", \"єва\", \"євим\", \"євої\", \"євій\", \"євою\", \"євому\",\n",
    "                   \"ива\", \"иву\", \"иві\", \"ивим\", \"ивої\", \"ивій\", \"ивою\", \"ивому\",\n",
    "                   \"іва\", \"іву\", \"іві\", \"івим\", \"івої\", \"івій\", \"івою\",\n",
    "                   \"їва\", \"їву\", \"їві\", \"ївим\", \"ївої\", \"ївій\", \"ївою\",\n",
    "                   \"кий\", \"кому\", \"кого\", \"ким\",\n",
    "                   \"ому\", \"ого\", \"ок\", \"к\", \"ка\", \"кої\", \"кою\", \"кій\", 'ки', 'ці',\n",
    "                   \"ко\", \"ку\", \"кові\", \"ком\",\n",
    "                   \"ець\", \"єць\", \"йця\", \"еця\", \"єця\", \"ця\", \"ь\", \"ецю\", \"єцю\", \"йцю\", \"цю\", \"цеві\", \"йцеві\", \"цем\", \"йцем\",\n",
    "                   \"ої\", \"ою\",\"ею\",\"ию\",\"ой\", \"им\", \"ім\", \"їм\", \"их\", \"іх\", \"їх\", \"ий\", \"ій\", \"ія\", \"ію\", \"ієм\", \"їй\", \n",
    "                   \"о\", \"а\", \"е\", \"є\", \"и\", \"і\", \"ї\", \"й\", \"у\", \"ю\", \"я\",\n",
    "                   \"ивих\", \"івих\", \"ївих\", \"ам\", \"ям\", \"ом\", \"ем\",\n",
    "                   \"ір\", \"ора\", \"ору\", \"ором\"]\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "    \n",
    "    def get_ner(self, text):\n",
    "        persons = []\n",
    "        try:\n",
    "            processor = Processor([PERSON])\n",
    "            result = processor(text)\n",
    "            for match in result.walk():\n",
    "                label = match.referent.label\n",
    "                if label == \"PERSON\":\n",
    "                    d = {\"raw\": str(match.referent.raw),\n",
    "                         \"last_name\": match.referent.lastname,\n",
    "                         \"first_name\": match.referent.firstname,\n",
    "                         \"middle_name\": match.referent.middlename\n",
    "                         }\n",
    "                    for child in match.children:\n",
    "                        if child.referent.label == \"PERSONPROPERTY\":\n",
    "                            d[\"label\"] = child.referent.name\n",
    "                        break\n",
    "                    persons.append(d)\n",
    "            return persons\n",
    "        except Exception as e:\n",
    "            print(\"ERROR in NER.get_ner: \", e)\n",
    "            return persons\n",
    "\n",
    "    @staticmethod\n",
    "    def find_unique_persons(persons):\n",
    "        d = defaultdict(list)\n",
    "        for person in persons:\n",
    "            try:\n",
    "                if '-' in person[\"last_name\"]:\n",
    "                    person[\"last_name\"] = person[\"last_name\"].split('-')[0]\n",
    "                if person[\"first_name\"].lower() == \"екатерина\":\n",
    "                    person[\"first_name\"] = \"КАТЕРИНА\"\n",
    "                stem_name = \"\"\n",
    "                for ch in NameSearch.NAME_ENDINGS:\n",
    "                    if person[\"last_name\"].lower().endswith(ch):\n",
    "                        stem_name = person[\"last_name\"].lower()[:-len(ch)]\n",
    "                        stem_name = stem_name[0].upper() + stem_name[1:]\n",
    "                        initials = person[\"first_name\"][0] + \".\" + person[\"middle_name\"][0] + \".\"\n",
    "                        break\n",
    "                if not stem_name:\n",
    "                    stem_name = person[\"last_name\"][0].upper() + person[\"last_name\"][1:].lower() \n",
    "                    initials = person[\"first_name\"][0] + \".\" + person[\"middle_name\"][0] + \".\"\n",
    "                d[(stem_name, initials)].append(person)\n",
    "            except Exception as e:\n",
    "                print(\"ERROR in NER.find_unique_persons: \", e)\n",
    "        return d\n",
    "\n",
    "    def search_person_algorithm(self, text):\n",
    "        names = []\n",
    "        trash = ('Судд', 'Головуюч', 'України')\n",
    "        exclude = ['\\\\', '|', ':', ';', '(', ')', '*', '’', '\\'', '`']\n",
    "        lst = ''.join(ch for ch in text if ch not in exclude)\n",
    "        lst = re.sub('\\n', ' $ ', lst).split(' ')\n",
    "        lst = [x for x in lst if x != '']\n",
    "        for i in range(2):\n",
    "            lst.insert(i, ' ')\n",
    "            lst.append(' ')\n",
    "        for i in range(len(lst)):\n",
    "            try:\n",
    "                if lst[i].isalpha() & lst[i][0].isupper() & lst[i+1][0].isupper() & (lst[i+1][1] == '.') & (not lst[i].startswith(trash)):\n",
    "                    if lst[i+2][0].isupper() & lst[i+2].endswith(('.', ',')):\n",
    "                        if (not (lst[i-1][0].isupper() & lst[i-1].endswith('.'))) | lst[i-1].endswith(','):\n",
    "                            names.append((lst[i], lst[i+1]+lst[i+2]))\n",
    "                    else:\n",
    "                        if (not (lst[i-1][0].isupper() & lst[i-1].endswith('.'))) | lst[i-1].endswith(','):\n",
    "                            names.append((lst[i], lst[i+1]))\n",
    "            except IndexError:\n",
    "                pass\n",
    "        return names\n",
    "    \n",
    "    @staticmethod\n",
    "    def persons_stemming(persons):\n",
    "        exclude = ['.', ',', ':', ';']\n",
    "        d = defaultdict(list)\n",
    "        for person in persons:\n",
    "            stem_name = \"\"\n",
    "            initials = \"\"\n",
    "            initial_stripped = ''.join(ch for ch in person[1] if ch not in exclude)\n",
    "            for ch in NameSearch.NAME_ENDINGS:\n",
    "                if person[0].lower().endswith(ch):\n",
    "                    stem_name = person[0].lower()[:-len(ch)]\n",
    "                    if len(stem_name) == 1:\n",
    "                        stem_name = stem_name[0].upper()\n",
    "                    else:\n",
    "                        try:\n",
    "                            stem_name = stem_name[0].upper() + stem_name[1:]\n",
    "                        except IndexError:\n",
    "                            break\n",
    "                    if len(initial_stripped) == 2:\n",
    "                        initials = initial_stripped[0] + '.' + initial_stripped[1] + '.'\n",
    "                        d[(stem_name, initials)].append(person)\n",
    "                    break\n",
    "            if not stem_name:\n",
    "                stem_name = person[0][0].upper() + person[0][1:].lower() \n",
    "                if len(initial_stripped) == 2:\n",
    "                    initials = initial_stripped[0] + '.' + initial_stripped[1] + '.'\n",
    "                    d[(stem_name, initials)].append(person)\n",
    "        return d\n",
    "\n",
    "    def name_searh(self): \n",
    "        persons_pullenti = NameSearch.find_unique_persons(self.get_ner(self.text))\n",
    "        persons_alg = NameSearch.persons_stemming(self.search_person_algorithm(self.text))\n",
    "        dct_alg = {}\n",
    "        for person in (set(persons_alg.keys()) - set(persons_pullenti.keys())):\n",
    "            dct_alg[person] = persons_alg[person]\n",
    "        dct = {**persons_pullenti, **dct_alg}\n",
    "        return dct\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UkrainianStemmer():\n",
    "    def __init__(self, word):\n",
    "        self.word = word\n",
    "        self.vowel = r'аеиоуюяіїє'  # http://uk.wikipedia.org/wiki/Голосний_звук\n",
    "        self.perfectiveground = r'(ив|ивши|ившись|ыв|ывши|ывшись((?<=[ая])(в|вши|вшись)))$'\n",
    "        # http://uk.wikipedia.org/wiki/Рефлексивне_дієслово\n",
    "        self.reflexive = r'(с[яьи])$'\n",
    "        # http://uk.wikipedia.org/wiki/Прикметник + http://wapedia.mobi/uk/Прикметник\n",
    "        self.adjective = r'(ими|ій|ий|а|е|ова|ове|ів|є|їй|єє|еє|я|ім|ем|им|ім|их|іх|ою|йми|іми|у|ю|ого|ому|ої)$'\n",
    "        # http://uk.wikipedia.org/wiki/Дієприкметник\n",
    "        self.participle = r'(ий|ого|ому|им|ім|а|ій|у|ою|ій|і|их|йми|их)$'\n",
    "        # http://uk.wikipedia.org/wiki/Дієслово\n",
    "        self.verb = r'(сь|ся|ив|ать|ять|у|ю|ав|али|учи|ячи|вши|ши|е|ме|ати|яти|є)$'\n",
    "        # http://uk.wikipedia.org/wiki/Іменник\n",
    "        self.noun = r'(а|ев|ов|е|ями|ами|еи|и|ей|ой|ий|й|иям|ям|ием|ем|ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я|і|ові|ї|ею|єю|ою|є|еві|ем|єм|ів|їв|ю)$'\n",
    "        self.rvre = r'[аеиоуюяіїє]'\n",
    "        self.derivational = r'[^аеиоуюяіїє][аеиоуюяіїє]+[^аеиоуюяіїє]+[аеиоуюяіїє].*(?<=о)сть?$'\n",
    "        self.RV = ''\n",
    "\n",
    "    def ukstemmer_search_preprocess(self, word):\n",
    "        word = word.lower()\n",
    "        word = word.replace(\"'\", \"\")\n",
    "        word = word.replace(\"ё\", \"е\")\n",
    "        word = word.replace(\"ъ\", \"ї\")\n",
    "        return word\n",
    "\n",
    "    def s(self, st, reg, to):\n",
    "        orig = st\n",
    "        self.RV = re.sub(reg, to, st)\n",
    "        return (orig != self.RV)\n",
    "\n",
    "    def stem_word(self):\n",
    "        word = self.ukstemmer_search_preprocess(self.word)\n",
    "        if not re.search('[аеиоуюяіїє]', word):\n",
    "            stem = word\n",
    "        else:\n",
    "            p = re.search(self.rvre, word)\n",
    "            start = word[0:p.span()[1]]\n",
    "            self.RV = word[p.span()[1]:]\n",
    "\n",
    "            # Step 1\n",
    "            if not self.s(self.RV, self.perfectiveground, ''):\n",
    "\n",
    "                self.s(self.RV, self.reflexive, '')\n",
    "                if self.s(self.RV, self.adjective, ''):\n",
    "                    self.s(self.RV, self.participle, '')\n",
    "                else:\n",
    "                    if not self.s(self.RV, self.verb, ''):\n",
    "                        self.s(self.RV, self.noun, '')\n",
    "            # Step 2\n",
    "            self.s(self.RV, 'и$', '')\n",
    "\n",
    "            # Step 3\n",
    "            if re.search(self.derivational, self.RV):\n",
    "                self.s(self.RV, 'ость$', '')\n",
    "\n",
    "            # Step 4\n",
    "            if self.s(self.RV, 'ь$', ''):\n",
    "                self.s(self.RV, 'ейше?$', '')\n",
    "                self.s(self.RV, 'нн$', u'н')\n",
    "\n",
    "            stem = start + self.RV\n",
    "        return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeaturesForNames():\n",
    "    \n",
    "    def __init__(self, file_name, text, persons):\n",
    "        self.text = text\n",
    "        self.persons = persons\n",
    "        self.file = file_name\n",
    "        \n",
    "    @staticmethod\n",
    "    def person_indexes(name, initials, text):\n",
    "        \"\"\"\n",
    "        params: name - last name of person\n",
    "        initials - initials of person\n",
    "        text - document to depersonalize\n",
    "        returns: lists of indexes\n",
    "        \"\"\"\n",
    "        indexes = []\n",
    "        exclude = ['-','\\\\', '|', ';', ',', '(', ')', '*', '’', '\\'','`']\n",
    "        lst = ''.join(ch for ch in text if ch not in exclude)\n",
    "        pat1 = r':'\n",
    "        pat2 = r'\\n'\n",
    "        combined_pat = r'|'.join((pat1, pat2))\n",
    "        lst = re.sub(combined_pat, ' ', lst).split(' ')\n",
    "        lst = [x for x in lst if x != '']\n",
    "        for i in range(2):\n",
    "            lst.insert(i, ' ')\n",
    "            lst.append(' ')\n",
    "        for i in range(len(lst)):\n",
    "            try:\n",
    "                if (lst[i].startswith((name,name.upper())) & ((lst[i-1].endswith(initials) | lst[i+1].startswith(initials)) | \\\n",
    "                                              ((initials[0] == lst[i+1][0]) & (initials[2] == lst[i+2][0])) |\\\n",
    "                                              (initials[0] == lst[i+1][0]) |\\\n",
    "                                              ((initials[0] == lst[i-2][0]) & (initials[2] == lst[i-1][0])) |\\\n",
    "                                              (initials[0] == lst[i-1][0]))) |\\\n",
    "                   lst[i].startswith(initials+name) | (lst[i].startswith(name) & lst[i].endswith(initials)):\n",
    "                    indexes.append(i)\n",
    "            except IndexError:\n",
    "                pass        \n",
    "        return indexes, len(lst)\n",
    "\n",
    "    \n",
    "    def features(self):\n",
    "        \"\"\"\n",
    "        params: name - last name of person\n",
    "        initials - initials of person\n",
    "        text - document to depersonalize\n",
    "        returns: lists of indexes\n",
    "        \"\"\"\n",
    "        judge_indexes = []\n",
    "        prosecutor_indexes = []\n",
    "        defence_indexes = []\n",
    "        secretary_indexes = []\n",
    "        notary_indexes = []\n",
    "        convict_indexes = []\n",
    "        arbitration_indexes = []\n",
    "        plaintiff_indexes = []\n",
    "        defendant_indexes = []\n",
    "        detective_indexes = []\n",
    "        liquidator_indexes = []\n",
    "        third_party_indexes = []\n",
    "        registrar_indexes = []\n",
    "        witness_indexes = []\n",
    "        accused_indexes = []\n",
    "        suspect_indexes = []\n",
    "        victim_indexes = []\n",
    "        representative_indexes = []\n",
    "        overhaul_indexes = []\n",
    "        head_indexes = []\n",
    "        statement_indexes = []\n",
    "        debtor_indexes = []\n",
    "        agent_indexes = []\n",
    "        famous_indexes = []\n",
    "        president_indexes = []\n",
    "        quotes_indexes = []\n",
    "        judge = ('судд')\n",
    "        prosecutor = ('прокурор')\n",
    "        defence = ('захисник', 'адвокат')\n",
    "        secretary = ('секретар')\n",
    "        notary = ('нотаріус', 'перекладач')\n",
    "        convict = ('засуджен')\n",
    "        arbitration = (('арбітражн'), ('керуюч'))\n",
    "        plaintiff = ('позивач', 'позов')\n",
    "        defendant = ('відповідач')\n",
    "        detective = ('слідч', 'детектив')\n",
    "        liquidator = ('ліквідатор')\n",
    "        third_party = (('трет'), ('особ'))\n",
    "        registrar = ('реєстратор')\n",
    "        witness = ('свідок', 'свідк', 'показ')\n",
    "        accused = ('звинувачуван', 'звинувачен', 'обвинувачуван','обвинувачен')\n",
    "        suspect = ('підозрюван')\n",
    "        victim = ('потерпілий')\n",
    "        representative = ('представни')\n",
    "        overhaul = (('керуюч'), ('санацією'))\n",
    "        head = ('голова', 'голові', 'головою', 'голови', 'начальн', 'керівник', 'директор')\n",
    "        statement = ('заяв')\n",
    "        debtor = ('боржник')\n",
    "        agent = ('уповноважен')\n",
    "        famous = ('ім.', 'імені')\n",
    "        president = (('президент', 'україн'))\n",
    "        quotes = ('\\\"', '«', '»', '”', '“')\n",
    "        exclude = ['-', '\\\\', '|', ':', ';', ',', '(', ')', '*', '’', '\\'', '`']\n",
    "        lst = ''.join(ch for ch in self.text if ch not in exclude)\n",
    "        lst = re.sub('\\n', ' ', lst).split(' ')\n",
    "        lst = [x for x in lst if x != '']\n",
    "        for i in range(2):\n",
    "            lst.insert(i, ' ')\n",
    "            lst.append(' ')\n",
    "        for i in range(len(lst)):\n",
    "            try:\n",
    "                if lst[i].lower().startswith(judge):\n",
    "                    judge_indexes.append(i)\n",
    "                if lst[i].lower().startswith(prosecutor):\n",
    "                    prosecutor_indexes.append(i)\n",
    "                if lst[i].lower().startswith(defence):\n",
    "                    defence_indexes.append(i)\n",
    "                if lst[i].lower().startswith(secretary):\n",
    "                    secretary_indexes.append(i)\n",
    "                if lst[i].lower().startswith(notary):\n",
    "                    notary_indexes.append(i)\n",
    "                if lst[i].lower().startswith(convict):\n",
    "                    convict_indexes.append(i)\n",
    "                if lst[i].lower().startswith(arbitration[0]) & lst[i+1].lower().startswith(arbitration[1]):\n",
    "                    arbitration_indexes.append(i+1)\n",
    "                if lst[i].lower().startswith(plaintiff):\n",
    "                    plaintiff_indexes.append(i)\n",
    "                if lst[i].lower().startswith(defendant):\n",
    "                    defendant_indexes.append(i)\n",
    "                if lst[i].lower().startswith(detective):\n",
    "                    detective_indexes.append(i)\n",
    "                if lst[i].lower().startswith(liquidator):\n",
    "                    liquidator_indexes.append(i)\n",
    "                if lst[i].lower().startswith(third_party[0]) & lst[i+1].lower().startswith(third_party[1]):\n",
    "                    third_party_indexes.append(i+1)\n",
    "                if lst[i].lower().startswith(registrar):\n",
    "                    registrar_indexes.append(i)\n",
    "                if lst[i].lower().startswith(witness):\n",
    "                    witness_indexes.append(i)\n",
    "                if lst[i].lower().startswith(accused):\n",
    "                    accused_indexes.append(i)\n",
    "                if lst[i].lower().startswith(suspect):\n",
    "                    suspect_indexes.append(i)\n",
    "                if lst[i].lower().startswith(victim):\n",
    "                    victim_indexes.append(i)\n",
    "                if lst[i].lower().startswith(representative):\n",
    "                    representative_indexes.append(i)\n",
    "                if lst[i].lower().startswith(overhaul[0]) & lst[i+1].lower().startswith(overhaul[1]):\n",
    "                    overhaul_indexes.append(i+1)\n",
    "                if lst[i].lower().startswith(head):\n",
    "                    head_indexes.append(i)\n",
    "                if lst[i].lower().startswith(statement):\n",
    "                    statement_indexes.append(i)\n",
    "                if lst[i].lower().startswith(debtor):\n",
    "                    debtor_indexes.append(i)\n",
    "                if lst[i].lower().startswith(agent):\n",
    "                    agent_indexes.append(i)\n",
    "                if lst[i].lower().startswith(famous):\n",
    "                    famous_indexes.append(i)\n",
    "                if lst[i].lower().startswith(president[0]) & lst[i+1].lower().startswith(president[1]):\n",
    "                    president_indexes.append(i+1)\n",
    "                if any([x in lst[i] for x in quotes]):\n",
    "                    quotes_indexes.append(i)\n",
    "            except IndexError:\n",
    "                pass        \n",
    "        return judge_indexes, prosecutor_indexes, defence_indexes, secretary_indexes, \\\n",
    "                notary_indexes, convict_indexes, arbitration_indexes, plaintiff_indexes, defendant_indexes, \\\n",
    "                detective_indexes, liquidator_indexes, third_party_indexes, registrar_indexes, witness_indexes, \\\n",
    "                accused_indexes, suspect_indexes, victim_indexes, representative_indexes, overhaul_indexes, head_indexes, \\\n",
    "                statement_indexes, debtor_indexes, agent_indexes, famous_indexes, president_indexes, quotes_indexes\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def pseudo_label(name, initials, text):\n",
    "        dct = defaultdict(list)\n",
    "        exclude = ['\\\\', '|', ':', ';', ',', '(', ')', '*', '’', '\\'', '`']\n",
    "        lst = ''.join(ch for ch in text if ch not in exclude)\n",
    "        lst = re.sub('\\n', ' ', lst).split(' ')\n",
    "        lst = [x for x in lst if x != '']\n",
    "        for i in range(2):\n",
    "            lst.insert(i, ' ')\n",
    "            lst.append(' ')\n",
    "        for i in range(len(lst)):\n",
    "            try:\n",
    "                if ((lst[i].startswith(name) & ((initials == lst[i-1]) | (initials == lst[i+1]) | \\\n",
    "                                              ((initials[0] == lst[i+1][0]) & (initials[2] == lst[i+2][0])) |\\\n",
    "                                              (initials[0] == lst[i+1][0]) |\\\n",
    "                                              ((initials[0] == lst[i-2][0]) & (initials[2] == lst[i-1][0])) |\\\n",
    "                                              (initials[0] == lst[i-1][0]))) |\\\n",
    "                   lst[i].startswith(initials+name) | (lst[i].startswith(name) & lst[i].endswith(initials))) & (lst[i-1] == '-'):\n",
    "                    dct[name+' '+initials] = ''.join(ch for ch in lst[i-2] if ch not in exclude)\n",
    "            except IndexError:\n",
    "                pass        \n",
    "        return dct\n",
    "    \n",
    "    \n",
    "    def court_type(self):\n",
    "        court_type = []\n",
    "        exclude = ['\\\\', '|', ':', ';', '(', ')', '*', '’', '\\'', '`']\n",
    "        lst = ''.join(ch for ch in self.text if ch not in exclude)\n",
    "        lst = re.sub('\\n', ' ', lst).split(' ')\n",
    "        lst = [x for x in lst if x != '']\n",
    "        stop = []\n",
    "        for i in lst:\n",
    "            if i.lower().startswith('судд'):\n",
    "                stop.append(i.lower())\n",
    "            if (i.lower() == 'суд') | (i.lower() == 'суду'):\n",
    "                break\n",
    "            else:\n",
    "                court_type.append(i.lower())\n",
    "        try:\n",
    "            answer = ' '.join(court_type[court_type.index(stop[-1])+1:])\n",
    "        except (ValueError, IndexError):\n",
    "            answer = ' '.join(court_type).replace('![]herb.gif','')\n",
    "        return answer\n",
    "    \n",
    "    def make_dataframe(self):\n",
    "        persons = []\n",
    "        labels = []\n",
    "        pseudo_labels = []\n",
    "        person_index = []\n",
    "        file = [self.file]\n",
    "        court_type = [self.file, self.court_type()]\n",
    "        feature = [self.file, self.features()]\n",
    "        for person in self.persons:\n",
    "            person_index.append(FeaturesForNames.person_indexes(person[0], person[1], self.text))\n",
    "            persons.append(person)\n",
    "            label = []\n",
    "            try:\n",
    "                for i in self.persons[person]:\n",
    "                    if 'label' in i.keys():\n",
    "                        label.append(i['label'])\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            labels.append(label)\n",
    "            if FeaturesForNames.pseudo_label(person[0], person[1], self.text):\n",
    "                pseudo_labels.append(list(FeaturesForNames.pseudo_label(person[0], person[1], self.text).values()))\n",
    "            else:\n",
    "                pseudo_labels.append([])\n",
    "        data = pd.DataFrame({'person': persons, 'person_indexes': [person_index[i][0] for i in range(len(person_index))],\n",
    "                             'length_doc' : [person_index[i][1] for i in range(len(person_index))], \n",
    "                             'labels': labels, 'pseudo_labels': pseudo_labels, 'file_name': file*len(persons)\n",
    "                            })\n",
    "        court_types = pd.DataFrame({'file_name': [court_type[0]], 'court_type': [court_type[1]]})\n",
    "        features = pd.DataFrame({'file_name': [feature[0]], 'judge': [feature[1][0]],\n",
    "                                 'prosecutor': [feature[1][1]], 'defence': [feature[1][2]], \n",
    "                                 'secretary': [feature[1][3]] , 'notary': [feature[1][4]], \n",
    "                                 'convict': [feature[1][5]], 'arbitration': [feature[1][6]],  \n",
    "                                 'plaintiff': [feature[1][7]], 'defendant': [feature[1][8]],\n",
    "                                 'detective': [feature[1][9]], 'liquidator': [feature[1][10]],  \n",
    "                                 'third_party': [feature[1][11]], 'registrar': [feature[1][12]],  \n",
    "                                 'witness': [feature[1][13]], 'accused': [feature[1][14]],  \n",
    "                                 'suspect': [feature[1][15]], 'victim': [feature[1][16]],\n",
    "                                 'representative': [feature[1][17]], 'overhaul': [feature[1][18]], \n",
    "                                 'head': [feature[1][19]], 'statement': [feature[1][20]], \n",
    "                                 'debtor': [feature[1][21]], 'agent': [feature[1][22]],\n",
    "                                 'famous': [feature[1][23]], 'president': [feature[1][24]],\n",
    "                                 'quotes': [feature[1][25]]\n",
    "                                })\n",
    "        data = data.merge(features, on='file_name', how='left').merge(court_types, on='file_name', how='left')\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
